{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOYmK7LCkh8N"
      },
      "source": [
        "## Intro to Machine Learning\n",
        "\n",
        "*Welcome to Machine Learning Housing Corp.! Your task is to predict median house values in Californian districts, given a number of features from these districts.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8j6n_dIkh8O"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWdlG3bYkh8O"
      },
      "source": [
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "TzmcC8okkh8O"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"end_to_end_project\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "# Define a function to save the figures\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdyYQK_Lkh8P"
      },
      "source": [
        "# Get the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CNSxCX-kh8P"
      },
      "source": [
        "## Download the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "hFPLoyWQkh8P"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "#Get the path to the file\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "# Write and call a function to fetch the data\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "6gfibsKOkh8P"
      },
      "outputs": [],
      "source": [
        "fetch_housing_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "s56q8GCTkh8P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Write and call a function to load the data\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGBJXm4Jkh8P"
      },
      "source": [
        "## Take a Quick Look at the Data Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECWeGc3ekh8P",
        "outputId": "90d107ab-42d7-4a89-a959-d53ea1726110"
      },
      "outputs": [],
      "source": [
        "housing = load_housing_data()\n",
        "housing.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae7ROTRNkh8Q",
        "outputId": "b8786125-98ae-4536-e690-5df2416d5e91"
      },
      "outputs": [],
      "source": [
        "housing.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zumnB4jIkh8Q",
        "outputId": "a7482a2a-e73f-4470-f0b7-ebe6bd3ade64"
      },
      "outputs": [],
      "source": [
        "housing[\"ocean_proximity\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6NxRSA7kh8Q",
        "outputId": "bc0f8664-713f-41b2-8b49-7d1cbd1a7350"
      },
      "outputs": [],
      "source": [
        "housing.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_IoRGADkh8Q",
        "outputId": "2bed05c4-a27a-4922-affb-1b62c2ab2f9c"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "housing.hist(bins=50, figsize=(20,15))\n",
        "save_fig(\"attribute_histogram_plots\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCJLEiC_kh8Q"
      },
      "source": [
        "## Create a Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "gxXEyKTbkh8Q"
      },
      "outputs": [],
      "source": [
        "# to make this notebook's output identical at every run\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "iSeWrDYnkh8Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Write and call a function to split the training set\n",
        "def split_train_test(data, test_ratio):\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w1qVQj5kh8Q",
        "outputId": "25bf0340-7d46-4e22-aaee-06322b9bb7b9"
      },
      "outputs": [],
      "source": [
        "train_set, test_set = split_train_test(housing, 0.2)\n",
        "\n",
        "# What is the length of the training set?\n",
        "len(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF8mGDfLkh8Q",
        "outputId": "ff8a93c1-c1c4-4fd8-e344-641977a7d281"
      },
      "outputs": [],
      "source": [
        "# What is the length of the test set?\n",
        "len(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "15mM6ReIkh8Q"
      },
      "outputs": [],
      "source": [
        "from zlib import crc32\n",
        "\n",
        "# check the test set\n",
        "def test_set_check(identifier, test_ratio):\n",
        "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
        "\n",
        "# splitting the trainning set by id\n",
        "def split_train_test_by_id(data, test_ratio, id_column):\n",
        "    ids = data[id_column]\n",
        "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
        "    return data.loc[~in_test_set], data.loc[in_test_set]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqUYaWg4kh8R",
        "outputId": "0377f8ff-29ec-4160-9852-b63aab93e3cc"
      },
      "outputs": [],
      "source": [
        "housing[\"median_income\"].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Wms2It6Hkh8R"
      },
      "outputs": [],
      "source": [
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
        "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "                               labels=[1, 2, 3, 4, 5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2fLSmEkkh8R",
        "outputId": "2404f13e-f04e-4ee1-fa7d-cebcbac82252"
      },
      "outputs": [],
      "source": [
        "housing[\"income_cat\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy8_WyMFkh8R",
        "outputId": "31285113-b161-4dc3-8d52-0cd969ec8847"
      },
      "outputs": [],
      "source": [
        "housing[\"income_cat\"].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "gFJD1AkFkh8R"
      },
      "outputs": [],
      "source": [
        "# splitting the data using stratified shuffle split\n",
        "np.int = np.int64\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQJVKP1akh8R",
        "outputId": "9b77fdb6-b76b-4b2c-abc0-c7011c736b40"
      },
      "outputs": [],
      "source": [
        "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1WIAOMqkh8R",
        "outputId": "e9f02511-d115-4075-9c63-bdb715b0643c"
      },
      "outputs": [],
      "source": [
        "housing[\"income_cat\"].value_counts() / len(housing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "WyR7ffdLkh8R"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def income_cat_proportions(data):\n",
        "    return data[\"income_cat\"].value_counts() / len(data)\n",
        "\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
        "\n",
        "compare_props = pd.DataFrame({\n",
        "    \"Overall\": income_cat_proportions(housing),\n",
        "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
        "    \"Random\": income_cat_proportions(test_set),\n",
        "}).sort_index()\n",
        "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
        "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9DzHySLkh8U",
        "outputId": "3a259257-55a1-4dd3-f35f-10804d6e3960"
      },
      "outputs": [],
      "source": [
        "compare_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "QfaonXHlkh8Z"
      },
      "outputs": [],
      "source": [
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uuAzzckkh8Z"
      },
      "source": [
        "# Discover and Visualize the Data to Gain Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Hjj9kKyKkh8Z"
      },
      "outputs": [],
      "source": [
        "housing = strat_train_set.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMMvHnd5kh8Z"
      },
      "source": [
        "## Visualizing Geographical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGlrOq12kh8Z",
        "outputId": "91a8ecc4-c850-41ce-c1a9-8d77968a83e9"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n",
        "save_fig(\"bad_visualization_plot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69qlh0nikh8Z",
        "outputId": "98ebd987-2a9f-401d-98a2-d9fb1ce3cfd4"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\n",
        "save_fig(\"better_visualization_plot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SW_0eQOkh8Z"
      },
      "source": [
        "The argument `sharex=False` fixes a display bug (the x-axis values and legend were not displayed). This is a temporary fix (see: https://github.com/pandas-dev/pandas/issues/10611 ). Thanks to Wilmer Arellano for pointing it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SALy4HDnkh8Z",
        "outputId": "f42133d3-1828-4142-bf87-df0913140b64"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
        "             s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
        "             c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
        "             sharex=False)\n",
        "plt.legend()\n",
        "save_fig(\"housing_prices_scatterplot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP_ojEonkh8Z",
        "outputId": "95a3e895-4d80-4238-ebb7-56ebbbb44a1d"
      },
      "outputs": [],
      "source": [
        "# Download the California image\n",
        "images_path = os.path.join(PROJECT_ROOT_DIR, \"images\", \"end_to_end_project\")\n",
        "os.makedirs(images_path, exist_ok=True)\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "filename = \"california.png\"\n",
        "print(\"Downloading\", filename)\n",
        "url = DOWNLOAD_ROOT + \"images/end_to_end_project/\" + filename\n",
        "urllib.request.urlretrieve(url, os.path.join(images_path, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMCWNjdVkh8a",
        "outputId": "91387ec4-2ebc-4995-f764-cf077846120b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\n",
        "california_img=mpimg.imread(os.path.join(images_path, filename))\n",
        "ax = housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", figsize=(10,7),\n",
        "                  s=housing['population']/100, label=\"Population\",\n",
        "                  c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),\n",
        "                  colorbar=False, alpha=0.4)\n",
        "plt.imshow(california_img, extent=[-124.55, -113.80, 32.45, 42.05], alpha=0.5,\n",
        "           cmap=plt.get_cmap(\"jet\"))\n",
        "plt.ylabel(\"Latitude\", fontsize=14)\n",
        "plt.xlabel(\"Longitude\", fontsize=14)\n",
        "\n",
        "prices = housing[\"median_house_value\"]\n",
        "tick_values = np.linspace(prices.min(), prices.max(), 11)\n",
        "cbar = plt.colorbar(ticks=tick_values/prices.max())\n",
        "cbar.ax.set_yticklabels([\"$%dk\"%(round(v/1000)) for v in tick_values], fontsize=14)\n",
        "cbar.set_label('Median House Value', fontsize=16)\n",
        "\n",
        "plt.legend(fontsize=16)\n",
        "save_fig(\"california_housing_prices_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-wdWAFbkh8a"
      },
      "source": [
        "## Looking for Correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "upkC1zQ0kh8a"
      },
      "outputs": [],
      "source": [
        "corr_matrix = housing.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGwt8rECkh8a",
        "outputId": "69c6d53e-b70e-4964-f29d-6634ff179ad1"
      },
      "outputs": [],
      "source": [
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-YWoecFkh8a",
        "outputId": "f9a04249-bb9f-46e6-d5c1-fe42d3e6b3a3"
      },
      "outputs": [],
      "source": [
        "# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
        "              \"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))\n",
        "save_fig(\"scatter_matrix_plot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOgUMxfIkh8a",
        "outputId": "997aaa56-30e0-4902-d36f-251ad26390d2"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
        "             alpha=0.1)\n",
        "plt.axis([0, 16, 0, 550000])\n",
        "save_fig(\"income_vs_house_value_scatterplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUE0Z57xkh8a"
      },
      "source": [
        "## Experimenting with Attribute Combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "j9TKJqWrkh8a"
      },
      "outputs": [],
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLcXD8n4kh8a",
        "outputId": "fb5ca2e1-2f76-4937-b603-5b0d836a8eec"
      },
      "outputs": [],
      "source": [
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUclm5kGkh8a",
        "outputId": "48841b81-8b8e-41c4-f05d-bff9c5c97428"
      },
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"rooms_per_household\", y=\"median_house_value\",\n",
        "             alpha=0.2)\n",
        "plt.axis([0, 5, 0, 520000])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dHcMb_akh8a",
        "outputId": "c779d194-1791-450c-fe1c-034727ed74b5"
      },
      "outputs": [],
      "source": [
        "housing.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGH-SvWEkh8a"
      },
      "source": [
        "# Prepare the Data for Machine Learning Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "r2j9oQZEkh8a"
      },
      "outputs": [],
      "source": [
        "housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnWXbDZlkh8a"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWxoPLtHkh8a"
      },
      "source": [
        "In the book 3 options are listed:\n",
        "\n",
        "```python\n",
        "housing.dropna(subset=[\"total_bedrooms\"])    # option 1\n",
        "housing.drop(\"total_bedrooms\", axis=1)       # option 2\n",
        "median = housing[\"total_bedrooms\"].median()  # option 3\n",
        "housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
        "```\n",
        "\n",
        "To demonstrate each of them, let's create a copy of the housing dataset, but keeping only the rows that contain at least one null. Then it will be easier to visualize exactly what each option does:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLrLDm5Qkh8a",
        "outputId": "8027bba8-56d1-4ddb-a939-b5bf161a7dc5"
      },
      "outputs": [],
      "source": [
        "sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\n",
        "sample_incomplete_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6kqLkljkh8a",
        "outputId": "c9299cad-616c-4e91-e94f-a7dbaf85a35b"
      },
      "outputs": [],
      "source": [
        "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # option 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-el-BHL4kh8a",
        "outputId": "545ea678-740c-4637-da08-fc23118317c3"
      },
      "outputs": [],
      "source": [
        "sample_incomplete_rows.drop(\"total_bedrooms\", axis=1)       # option 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "aqqSX0wvkh8a"
      },
      "outputs": [],
      "source": [
        "median = housing[\"total_bedrooms\"].median()\n",
        "sample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # option 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isNfRQPvkh8b",
        "outputId": "7d0e67e4-84a4-4189-f7cf-0cfe7b18611f"
      },
      "outputs": [],
      "source": [
        "sample_incomplete_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "sun9w5mOkh8b"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "np.float = float    \n",
        "\n",
        "imputer = SimpleImputer(strategy=\"median\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCmSPs9Jkh8b"
      },
      "source": [
        "Remove the text attribute because median can only be calculated on numerical attributes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "41CZsidykh8b"
      },
      "outputs": [],
      "source": [
        "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
        "# alternatively: housing_num = housing.select_dtypes(include=[np.number])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLyz4egxkh8b",
        "outputId": "274af218-24ee-4759-d715-38d799a1ae89"
      },
      "outputs": [],
      "source": [
        "imputer.fit(housing_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE5dxOWykh8b",
        "outputId": "ad795028-e463-483a-88cf-69b8403aef08"
      },
      "outputs": [],
      "source": [
        "imputer.statistics_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zyvfTM_kh8b"
      },
      "source": [
        "Check that this is the same as manually computing the median of each attribute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS6w0sRIkh8b",
        "outputId": "46d356aa-670a-4049-be75-a3e5936c9356"
      },
      "outputs": [],
      "source": [
        "housing_num.median().values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ULbpULJkh8b"
      },
      "source": [
        "Transform the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "lnSEVOFikh8b"
      },
      "outputs": [],
      "source": [
        "X = imputer.transform(housing_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "0bWeOmX8kh8b"
      },
      "outputs": [],
      "source": [
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
        "                          index=housing.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXrBHUEGkh8b",
        "outputId": "dfde64a5-8417-4088-a876-f9ef7a7a7940"
      },
      "outputs": [],
      "source": [
        "housing_tr.loc[sample_incomplete_rows.index.values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7wpLZUrkh8b",
        "outputId": "9f7b438f-4c00-40a1-863d-1b4d83298839"
      },
      "outputs": [],
      "source": [
        "imputer.strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "JDUbRx_Vkh8b"
      },
      "outputs": [],
      "source": [
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
        "                          index=housing_num.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-teYJklkh8b",
        "outputId": "2c5a861b-e94f-4a9d-8b4b-db77dd59ef66"
      },
      "outputs": [],
      "source": [
        "housing_tr.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5RYuKcVkh8b"
      },
      "source": [
        "## Handling Text and Categorical Attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqtCAIQgkh8b"
      },
      "source": [
        "Now let's preprocess the categorical input feature, `ocean_proximity`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKR4KJ2ckh8b",
        "outputId": "639be355-dd7a-4332-ac0d-56fccf5e6b3f"
      },
      "outputs": [],
      "source": [
        "housing_cat = housing[[\"ocean_proximity\"]]\n",
        "housing_cat.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kn3mR4bkh8b",
        "outputId": "e073f74b-f000-430d-9361-8f92d852d3f4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "np.bool = bool\n",
        "\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
        "housing_cat_encoded[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuPX_uoDkh8b",
        "outputId": "341b0716-6f0d-42a2-dd7b-32153737178c"
      },
      "outputs": [],
      "source": [
        "ordinal_encoder.categories_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxBScmSikh8b",
        "outputId": "37f3508c-7836-4d9f-d41c-be41135250c6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_encoder = OneHotEncoder()\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "housing_cat_1hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gM2itx2kh8c"
      },
      "source": [
        "By default, the `OneHotEncoder` class returns a sparse array, but we can convert it to a dense array if needed by calling the `toarray()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVn0QvK6kh8c",
        "outputId": "a7fe5cc2-2f6d-4fb4-b9ac-1218dda84a54"
      },
      "outputs": [],
      "source": [
        "housing_cat_1hot.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN1mY88Akh8c"
      },
      "source": [
        "Alternatively, you can set `sparse=False` when creating the `OneHotEncoder`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giL4DwGakh8c",
        "outputId": "43808a58-53a9-4aa8-bed0-b519022417ab"
      },
      "outputs": [],
      "source": [
        "cat_encoder = OneHotEncoder(sparse=False)\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "housing_cat_1hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FGoty9fkh8c",
        "outputId": "6aa26ecb-01cd-44fe-bbf7-673471bf5f00"
      },
      "outputs": [],
      "source": [
        "cat_encoder.categories_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAB7WJB8kh8c"
      },
      "source": [
        "## Custom Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfIx4gjlkh8c"
      },
      "source": [
        "Let's create a custom transformer to add extra attributes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "NMv6EBH_kh8c"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# column index\n",
        "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, add_bedrooms_per_room=True): # no *args or **kargs\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    def fit(self, X, y=None):\n",
        "        return self  # nothing else to do\n",
        "    def transform(self, X):\n",
        "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
        "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
        "        if self.add_bedrooms_per_room:\n",
        "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
        "            return np.c_[X, rooms_per_household, population_per_household,\n",
        "                         bedrooms_per_room]\n",
        "        else:\n",
        "            return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVveTHkikh8c"
      },
      "source": [
        "Note that I hard coded the indices (3, 4, 5, 6) for concision and clarity in the book, but it would be much cleaner to get them dynamically, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "v9d2ZTHVkh8c"
      },
      "outputs": [],
      "source": [
        "col_names = \"total_rooms\", \"total_bedrooms\", \"population\", \"households\"\n",
        "rooms_ix, bedrooms_ix, population_ix, households_ix = [\n",
        "    housing.columns.get_loc(c) for c in col_names] # get the column indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43P8_9U1kh8c"
      },
      "source": [
        "Also, `housing_extra_attribs` is a NumPy array, we've lost the column names (unfortunately, that's a problem with Scikit-Learn). To recover a `DataFrame`, you could run this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EObqnm7Ckh8c",
        "outputId": "192166f2-966e-44e6-ee1b-39ed4bf6bdc6"
      },
      "outputs": [],
      "source": [
        "housing_extra_attribs = pd.DataFrame(\n",
        "    housing_extra_attribs,\n",
        "    columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"],\n",
        "    index=housing.index)\n",
        "housing_extra_attribs.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtXrAbBMkh8c"
      },
      "source": [
        "## Transformation Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuhljqlJkh8c"
      },
      "source": [
        "Now let's build a pipeline for preprocessing the numerical attributes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "aVdduV5akh8c"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('attribs_adder', CombinedAttributesAdder()),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRKq29xfkh8c",
        "outputId": "421763f1-5c1f-4c54-bd72-6b0272ed8d05"
      },
      "outputs": [],
      "source": [
        "housing_num_tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "sXhDFiq1kh8c"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n",
        "\n",
        "housing_prepared = full_pipeline.fit_transform(housing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBGsuL5dkh8d",
        "outputId": "0abcdad5-8912-4d48-e4ef-d12b62c36d05"
      },
      "outputs": [],
      "source": [
        "housing_prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXr0pPpSkh8d",
        "outputId": "ab5c1244-28b1-4f17-c7d3-793bb0ea4892"
      },
      "outputs": [],
      "source": [
        "housing_prepared.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDkYYS7Wkh8d"
      },
      "source": [
        "For reference, here is the old solution based on a `DataFrameSelector` transformer (to just select a subset of the Pandas `DataFrame` columns), and a `FeatureUnion`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "G-lmtsRakh8d"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# Create a class to select numerical or categorical columns\n",
        "class OldDataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, attribute_names):\n",
        "        self.attribute_names = attribute_names\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[self.attribute_names].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCzVzM-Fkh8d"
      },
      "source": [
        "Now let's join all these components into a big pipeline that will preprocess both the numerical and the categorical features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "H-H_H7bZkh8d"
      },
      "outputs": [],
      "source": [
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "old_num_pipeline = Pipeline([\n",
        "        ('selector', OldDataFrameSelector(num_attribs)),\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('attribs_adder', CombinedAttributesAdder()),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "old_cat_pipeline = Pipeline([\n",
        "        ('selector', OldDataFrameSelector(cat_attribs)),\n",
        "        ('cat_encoder', OneHotEncoder(sparse=False)),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "ZZFOBFzskh8d"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "old_full_pipeline = FeatureUnion(transformer_list=[\n",
        "        (\"num_pipeline\", old_num_pipeline),\n",
        "        (\"cat_pipeline\", old_cat_pipeline),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEq-krcxkh8d",
        "outputId": "bcf76eba-3003-4cc6-cdb6-3585b432c5e9"
      },
      "outputs": [],
      "source": [
        "old_housing_prepared = old_full_pipeline.fit_transform(housing)\n",
        "old_housing_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVRfZ_Fbkh8d"
      },
      "source": [
        "The result is the same as with the `ColumnTransformer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTMf5hDkh8d",
        "outputId": "343f107e-066a-46c7-cdba-483c22ba2bd0"
      },
      "outputs": [],
      "source": [
        "np.allclose(housing_prepared, old_housing_prepared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpJL_9j1kh8d"
      },
      "source": [
        "# Select and Train a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3ofM81Hkh8d"
      },
      "source": [
        "## Training and Evaluating on the Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2IHVw6ckh8d",
        "outputId": "8c99c681-fe6a-4f02-a21a-b02a86fbe9ac"
      },
      "outputs": [],
      "source": [
        "np.float = float\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ywqrxKnkh8d",
        "outputId": "1e9b557f-178d-4f4b-be71-a28d41504a54"
      },
      "outputs": [],
      "source": [
        "# let's try the full preprocessing pipeline on a few training instances\n",
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vW2eVk-kh8d"
      },
      "source": [
        "Compare against the actual values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bFNXWUWkh8d",
        "outputId": "1916e1dd-6e6b-4ea5-deaf-3c7194b8ac60"
      },
      "outputs": [],
      "source": [
        "print(\"Labels:\", list(some_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BccoFTK_kh8d",
        "outputId": "62e2892e-0884-4e9a-b578-5671e1c25f7d"
      },
      "outputs": [],
      "source": [
        "some_data_prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQW488BWkh8d",
        "outputId": "4058baba-4232-449d-c0af-b2a9c411e06b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "lin_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGijJAMskh8d"
      },
      "source": [
        "**Note**: since Scikit-Learn 0.22, you can get the RMSE directly by calling the `mean_squared_error()` function with `squared=False`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1-itUAZkh8d",
        "outputId": "3613ee4a-c38c-4a19-e773-2c2541f36f84"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "lin_mae = mean_absolute_error(housing_labels, housing_predictions)\n",
        "lin_mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6SUdCdzkh8d",
        "outputId": "15ebbebd-60d4-4f91-da9c-8e7cf1874853"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9673-NU8kh8e",
        "outputId": "23e78423-2793-44da-e405-2fc118805ee6"
      },
      "outputs": [],
      "source": [
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7mMNaIjkh8e"
      },
      "source": [
        "## Better Evaluation Using Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "aRC93Ctnkh8e"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "tree_rmse_scores = np.sqrt(-scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ujj8VQikh8e",
        "outputId": "3966716c-8099-48db-bb94-61ecc86a6d2a"
      },
      "outputs": [],
      "source": [
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())\n",
        "\n",
        "display_scores(tree_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K27JlHRnkh8e",
        "outputId": "f1fb9aac-30f8-420b-f574-6688fb3a5314"
      },
      "outputs": [],
      "source": [
        "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUIhYk1Vkh8e"
      },
      "source": [
        "**Note**: we specify `n_estimators=100` to be future-proof since the default value is going to change to 100 in Scikit-Learn 0.22 (for simplicity, this is not shown in the book)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcVEHyc1kh8e",
        "outputId": "9e480c1d-fc74-4007-cc21-641eafa7cc06"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "forest_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS7MPedYkh8e",
        "outputId": "52ed3709-94fb-49a5-cc93-8231b9d3891c"
      },
      "outputs": [],
      "source": [
        "housing_predictions = forest_reg.predict(housing_prepared)\n",
        "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "forest_rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Nbp4cPckh8e",
        "outputId": "d78f3a9c-e05a-4530-a751-0a663963fabf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
        "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "display_scores(forest_rmse_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n3lnYNwkh8e",
        "outputId": "7a7c749b-9256-4cb0-a4c9-bed564e38378"
      },
      "outputs": [],
      "source": [
        "scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "pd.Series(np.sqrt(-scores)).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHM5otXekh8e",
        "outputId": "7707c78a-7e15-49d1-970c-3dc144d76664"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svm_reg = SVR(kernel=\"linear\")\n",
        "svm_reg.fit(housing_prepared, housing_labels)\n",
        "housing_predictions = svm_reg.predict(housing_prepared)\n",
        "svm_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "svm_rmse = np.sqrt(svm_mse)\n",
        "svm_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc344ZuLkh8e"
      },
      "source": [
        "# Fine-Tune Your Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmKXsU8ckh8e"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0ThCgtxkh8e",
        "outputId": "973bb694-2569-4c59-c234-0abfbf7e51c0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    # try 12 (3×4) combinations of hyperparameters\n",
        "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
        "    # then try 6 (2×3) combinations with bootstrap set as False\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "  ]\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnw57Ttlkh8e"
      },
      "source": [
        "The best hyperparameter combination found:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae3WVLIZkh8e",
        "outputId": "7d1ce6e0-2ae9-40e5-89aa-6890c232eac6"
      },
      "outputs": [],
      "source": [
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GFqGaSNkh8e",
        "outputId": "c1adb4a7-1185-42d1-e2f2-cd08dc6a14ce"
      },
      "outputs": [],
      "source": [
        "grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtnRNyjzkh8e"
      },
      "source": [
        "Let's look at the score of each hyperparameter combination tested during the grid search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWDfqqw1kh8e",
        "outputId": "03b4d338-7104-45de-8b73-5574e32d2316"
      },
      "outputs": [],
      "source": [
        "cvres = grid_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa-iGkdikh8e",
        "outputId": "1d224f35-1021-4358-a175-11b6897c1201"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(grid_search.cv_results_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbTAy8D-kh8e"
      },
      "source": [
        "## Randomized Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWHiy75-kh8e",
        "outputId": "80ff68e8-71cc-4540-9706-b7b9218114c5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distribs = {\n",
        "        'n_estimators': randint(low=1, high=200),\n",
        "        'max_features': randint(low=1, high=8),\n",
        "    }\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
        "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
        "rnd_search.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1YZU24ekh8f",
        "outputId": "7636e67a-39b1-43b4-b4e4-4f0d68211c1c"
      },
      "outputs": [],
      "source": [
        "cvres = rnd_search.cv_results_\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "    print(np.sqrt(-mean_score), params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1H7jx1kkh8f"
      },
      "source": [
        "## Analyze the Best Models and Their Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJFH0quzkh8f",
        "outputId": "7ad795eb-453c-4306-f29e-2e812b0c6290"
      },
      "outputs": [],
      "source": [
        "feature_importances = grid_search.best_estimator_.feature_importances_\n",
        "feature_importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPCVDyQlkh8f",
        "outputId": "bb3b9a8a-60c8-422b-d31a-37266d2a8d1c"
      },
      "outputs": [],
      "source": [
        "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
        "#cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"] # old solution\n",
        "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
        "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
        "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
        "sorted(zip(feature_importances, attributes), reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWmdKOkOkh8f"
      },
      "source": [
        "## Evaluate Your System on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "vBRte5T0kh8f"
      },
      "outputs": [],
      "source": [
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoPdNxXfkh8f",
        "outputId": "d27a6fd7-67e6-4597-da70-9312092f7c55"
      },
      "outputs": [],
      "source": [
        "final_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0hGbsTrkh8f"
      },
      "source": [
        "We can compute a 95% confidence interval for the test RMSE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23l7ucynkh8f",
        "outputId": "9ccb58e5-f3fc-4765-8426-dd85dfaed640"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "confidence = 0.95\n",
        "squared_errors = (final_predictions - y_test) ** 2\n",
        "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
        "                         loc=squared_errors.mean(),\n",
        "                         scale=stats.sem(squared_errors)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84_mh-6gkh8f"
      },
      "source": [
        "We could compute the interval manually like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17T56uk-kh8f",
        "outputId": "fbc861e1-0b50-4a95-97be-ca6a000fad8d"
      },
      "outputs": [],
      "source": [
        "m = len(squared_errors)\n",
        "mean = squared_errors.mean()\n",
        "tscore = stats.t.ppf((1 + confidence) / 2, df=m - 1)\n",
        "tmargin = tscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
        "np.sqrt(mean - tmargin), np.sqrt(mean + tmargin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqqyO5l5kh8f"
      },
      "source": [
        "Alternatively, we could use a z-scores rather than t-scores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbfJ0yp9kh8f",
        "outputId": "40a5d235-bfb0-4c34-cccd-afe7f46ad941"
      },
      "outputs": [],
      "source": [
        "zscore = stats.norm.ppf((1 + confidence) / 2)\n",
        "zmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
        "np.sqrt(mean - zmargin), np.sqrt(mean + zmargin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CND7lF8kh8f"
      },
      "source": [
        "# Extra material"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3PHINJZkh8f"
      },
      "source": [
        "## A full pipeline with both preparation and prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCJrSkPpkh8f",
        "outputId": "808054e9-56e7-4f8e-b7cc-330bb9312545"
      },
      "outputs": [],
      "source": [
        "full_pipeline_with_predictor = Pipeline([\n",
        "        (\"preparation\", full_pipeline),\n",
        "        (\"linear\", LinearRegression())\n",
        "    ])\n",
        "\n",
        "full_pipeline_with_predictor.fit(housing, housing_labels)\n",
        "full_pipeline_with_predictor.predict(some_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0QIFU-Lkh8f"
      },
      "source": [
        "## Model persistence using joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "7-xtcnJTkh8f"
      },
      "outputs": [],
      "source": [
        "my_model = full_pipeline_with_predictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "uleZmmkZkh8f"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(my_model, \"my_model.pkl\") # DIFF\n",
        "#...\n",
        "my_model_loaded = joblib.load(\"my_model.pkl\") # DIFF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umq4xESKkh8f"
      },
      "source": [
        "## Example SciPy distributions for `RandomizedSearchCV`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgTPAyKhkh8f",
        "outputId": "1dc70db4-5d2a-41bb-b0f1-e010015fe9da"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import geom, expon\n",
        "geom_distrib=geom(0.5).rvs(10000, random_state=42)\n",
        "expon_distrib=expon(scale=1).rvs(10000, random_state=42)\n",
        "plt.hist(geom_distrib, bins=50)\n",
        "plt.show()\n",
        "plt.hist(expon_distrib, bins=50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X93YdG4_kh8g"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW56wZqxkh8h"
      },
      "source": [
        "## 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k41-znPGkh8h"
      },
      "source": [
        "Question: Try adding a transformer in the preparation pipeline to select only the most important attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "fPfvRElzkh8h"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "def indices_of_top_k(arr, k):\n",
        "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
        "\n",
        "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, feature_importances, k):\n",
        "        self.feature_importances = feature_importances\n",
        "        self.k = k\n",
        "    def fit(self, X, y=None):\n",
        "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[:, self.feature_indices_]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZONHT6Kckh8h"
      },
      "source": [
        "Note: this feature selector assumes that you have already computed the feature importances somehow (for example using a `RandomForestRegressor`). You may be tempted to compute them directly in the `TopFeatureSelector`'s `fit()` method, however this would likely slow down grid/randomized search since the feature importances would have to be computed for every hyperparameter combination (unless you implement some sort of cache)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQURwawHkh8h"
      },
      "source": [
        "Let's define the number of top features we want to keep:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "D4nujM6akh8h"
      },
      "outputs": [],
      "source": [
        "k = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wekVAfEckh8h"
      },
      "source": [
        "Now let's look for the indices of the top k features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzKDR9rPkh8h",
        "outputId": "47e4d34d-accb-4e1b-d014-244ed4805558"
      },
      "outputs": [],
      "source": [
        "top_k_feature_indices = indices_of_top_k(feature_importances, k)\n",
        "top_k_feature_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MWzA9ockh8h",
        "outputId": "db479ff7-8421-4354-ed60-fb0e4fc97830"
      },
      "outputs": [],
      "source": [
        "np.array(attributes)[top_k_feature_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NthGgGBZkh8h"
      },
      "source": [
        "Let's double check that these are indeed the top k features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-6ARp3kkh8h",
        "outputId": "e0e0817f-150b-4332-8d0c-b66192a56352"
      },
      "outputs": [],
      "source": [
        "sorted(zip(feature_importances, attributes), reverse=True)[:k]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXXHWTqFkh8h"
      },
      "source": [
        "Looking good... Now let's create a new pipeline that runs the previously defined preparation pipeline, and adds top k feature selection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "vaOBXbc-kh8h"
      },
      "outputs": [],
      "source": [
        "preparation_and_feature_selection_pipeline = Pipeline([\n",
        "    ('preparation', full_pipeline),\n",
        "    ('feature_selection', TopFeatureSelector(feature_importances, k))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "yKOCbfqWkh8h"
      },
      "outputs": [],
      "source": [
        "housing_prepared_top_k_features = preparation_and_feature_selection_pipeline.fit_transform(housing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGCQhX6kkh8h"
      },
      "source": [
        "Let's look at the features of the first 3 instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9X11yclkh8h",
        "outputId": "6b13f996-2c23-4649-90e1-9b187d961834"
      },
      "outputs": [],
      "source": [
        "housing_prepared_top_k_features[0:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i58jGHAokh8i"
      },
      "source": [
        "Now let's double check that these are indeed the top k features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "xoN271hLkh8i",
        "outputId": "352f908f-6c44-4b36-f937-afc5df6ff1d6"
      },
      "outputs": [],
      "source": [
        "housing_prepared[0:3, top_k_feature_indices]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovDQZIO0kh8i"
      },
      "source": [
        "Works great!  :)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nav_menu": {
      "height": "279px",
      "width": "309px"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
